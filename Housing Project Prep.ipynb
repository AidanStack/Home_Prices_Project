{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This is a notebook containing main functions / approaches neccessary to do pre-processing on the Kings County housing data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sklearn imports\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_validate\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statsmodel imports\n",
    "\n",
    "from statsmodels.formula.api import ols\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/kc_house_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-78c5b859d77c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data/kc_house_data.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    684\u001b[0m     )\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 946\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1176\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2006\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2008\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2009\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/kc_house_data.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./data/kc_house_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-01d0354b068e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train test split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'price'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'price'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Split the data out, specifying size of the split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Train test split\n",
    "y = df['price']\n",
    "X = df.drop('price', axis=1)\n",
    "\n",
    "# Split the data out, specifying size of the split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y,\n",
    "                                                    test_size=0.33,\n",
    "                                                    random_state=5\n",
    ")\n",
    "\n",
    "# Merge back together into one Train and Test dataset\n",
    "df_train = pd.concat([X_train, y_train], axis=1)\n",
    "df_test = pd.concat([X_test, y_test], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-116a6524557b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_train' is not defined"
     ]
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-9e77b9000d41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Maybe filter this for only the columns we're truly interested in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpairplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Check for linear relationships\n",
    "# Maybe filter this for only the columns we're truly interested in\n",
    "\n",
    "sns.pairplot(df_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-f41a456beae0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Check for multi collinearity among independent variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check for multi collinearity among independent variables\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "sns.heatmap(X_train.drop('id', axis=1).corr(), annot=True, ax=ax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-1baa86e51152>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Filter for only multicollinearity above a certain threshold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# zip the variable name columns (Which were only named level_0 and level_1 by default) in a new column named \"pairs\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Filter for only multicollinearity above a certain threshold\n",
    "\n",
    "test=X_train.corr().abs().stack().reset_index().sort_values(0, ascending=False)\n",
    "\n",
    "# zip the variable name columns (Which were only named level_0 and level_1 by default) in a new column named \"pairs\"\n",
    "test['pairs'] = list(zip(test.level_0, test.level_1))\n",
    "\n",
    "# set index to pairs\n",
    "test.set_index(['pairs'], inplace = True)\n",
    "\n",
    "#d rop level columns\n",
    "test.drop(columns=['level_1', 'level_0'], inplace = True)\n",
    "\n",
    "# rename correlation column as cc rather than 0\n",
    "test.columns = ['cc']\n",
    "\n",
    "# drop duplicates. This could be dangerous if you have variables perfectly correlated with variables other than themselves.\n",
    "# for the sake of exercise, kept it in.\n",
    "test.drop_duplicates(inplace=True)\n",
    "\n",
    "test[(test.cc>.6)] #& (test.cc <1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-71c7247c9d2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# # For each column,run a variance_inflaction_factor against all other columns to get a VIF Factor score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mvif\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"VIF\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvariance_inflation_factor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# # label the scores with their related columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Can also check for multicollinearity using statsmodel\n",
    "# Need to first filter for numerical variables\n",
    "\n",
    "# defining an empty dataframe to capture the VIF scores\n",
    "vif = pd.DataFrame()\n",
    "\n",
    "# # For each column,run a variance_inflaction_factor against all other columns to get a VIF Factor score\n",
    "vif[\"VIF\"] = [variance_inflation_factor(X_train.values, i) for i in range(len(X_train.columns))]\n",
    "\n",
    "# # label the scores with their related columns\n",
    "vif[\"features\"] = X_train.columns\n",
    "\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple model: what is most correlated with Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-d91004fb8d82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_train' is not defined"
     ]
    }
   ],
   "source": [
    "df_train.corr().price.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check residuals for normality and heteroskedacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate residuals for each model\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "train_preds = lr.predict(X_train)\n",
    "test_preds = lr.predict(X_test)\n",
    "\n",
    "train_residuals = y_train - train_preds\n",
    "test_residuals = y_test - test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of residuals\n",
    "plt.hist(train_residuals, label='Train')\n",
    "plt.hist(test_residuals, label='Test')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QQ plots are generally great tools for checking for normality.\n",
    "import statsmodels.api as sm\n",
    "\n",
    "sm.qqplot(train_residuals, line = 'r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check heteroskedacity of full model\n",
    "plt.scatter(train_preds, train_residuals, label='Train')\n",
    "plt.scatter(test_preds, test_residuals, label='Test')\n",
    "\n",
    "plt.axhline(y=0, color = 'red', label = '0')\n",
    "plt.xlabel('predictions')\n",
    "plt.ylabel('residuals')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For simple model\n",
    "\n",
    "# note that these residplots only work for single variables\n",
    "sns.residplot(x=X_train['TV'], y=y_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace data_pred with our actual dataframe\n",
    "\n",
    "data_log = pd.DataFrame([])\n",
    "data_log['logdisp'] = np.log(data_pred['displacement'])\n",
    "data_log['loghorse'] = np.log(data_pred['horsepower'])\n",
    "data_log['logweight'] = np.log(data_pred['weight'])\n",
    "data_log.hist(figsize  = [6, 6]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize columns\n",
    "\n",
    "Feature selection and engineering lecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From SK learn documentation\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "data = [[0, 0], [0, 0], [1, 1], [1, 1]]\n",
    "scaler = StandardScaler()\n",
    "print(scaler.fit(data))\n",
    "StandardScaler()\n",
    "print(scaler.mean_)\n",
    "[0.5 0.5]\n",
    "print(scaler.transform(data))\n",
    "[[-1. -1.]\n",
    " [-1. -1.]\n",
    " [ 1.  1.]\n",
    " [ 1.  1.]]\n",
    "print(scaler.transform([[2, 2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardization example from a lab\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "ss = StandardScaler()\n",
    "ss.fit(wine.drop('quality', axis=1))\n",
    "\n",
    "wine_scaled = ss.transform(wine.drop('quality', axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary variables\n",
    "import OrdinalEncoder from sklearn.preprocessing\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# Replace None with appropriate code\n",
    "\n",
    "\n",
    "# (1) Create a variable street_train that contains the\n",
    "# relevant column from X_train\n",
    "# (Use double brackets [[]] to get the appropriate shape)\n",
    "street_train = X_train[['Street']]\n",
    "\n",
    "# (2) Instantiate an OrdinalEncoder\n",
    "encoder_street = OrdinalEncoder()\n",
    "\n",
    "# (3) Fit the encoder on street_train\n",
    "encoder_street.fit(street_train)\n",
    "\n",
    "# Inspect the categories of the fitted encoder\n",
    "encoder_street.categories_[0]\n",
    "\n",
    "# (4) Transform street_train using the encoder and\n",
    "# assign the result to street_encoded_train\n",
    "street_encoded_train = encoder_street.transform(street_train)\n",
    "\n",
    "# Flatten for appropriate shape\n",
    "street_encoded_train = street_encoded_train.flatten()\n",
    "\n",
    "# Visually inspect street_encoded_train\n",
    "street_encoded_train\n",
    "\n",
    "\n",
    "# (5) Replace value of Street\n",
    "X_train[\"Street\"] = street_encoded_train\n",
    "\n",
    "# Visually inspect X_train\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple categories \n",
    "\n",
    "\n",
    "import OneHotEncoder from sklearn.preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# (1) Create a variable fireplace_qu_train\n",
    "# extracted from X_train\n",
    "# (double brackets due to shape expected by OHE)\n",
    "fireplace_qu_train = X_train[[\"FireplaceQu\"]]\n",
    "\n",
    "# (2) Instantiate a OneHotEncoder with categories=\"auto\",\n",
    "# sparse=False, and handle_unknown=\"ignore\"\n",
    "ohe = OneHotEncoder(categories='auto', sparse=False, handle_unknown='ignore')\n",
    "\n",
    "# # (3) Fit the encoder on fireplace_qu_train\n",
    "ohe.fit(fireplace_qu_train)\n",
    "\n",
    "# # Inspect the categories of the fitted encoder\n",
    "ohe.categories_\n",
    "\n",
    "\n",
    "# (4) Transform fireplace_qu_train using the encoder and\n",
    "# assign the result to fireplace_qu_encoded_train\n",
    "fireplace_qu_encoded_train = ohe.transform(fireplace_qu_train)\n",
    "\n",
    "# Visually inspect fireplace_qu_encoded_train\n",
    "fireplace_qu_encoded_train\n",
    "\n",
    "# Run this cell without changes\n",
    "\n",
    "# (5a) Make the transformed data into a dataframe\n",
    "fireplace_qu_encoded_train = pd.DataFrame(\n",
    "    # Pass in NumPy array\n",
    "    fireplace_qu_encoded_train,\n",
    "    # Set the column names to the categories found by OHE\n",
    "    columns=ohe.categories_[0],\n",
    "    # Set the index to match X_train's index\n",
    "    index=X_train.index\n",
    ")\n",
    "\n",
    "# Visually inspect new dataframe\n",
    "fireplace_qu_encoded_train\n",
    "\n",
    "# (5b) Drop original FireplaceQu column\n",
    "X_train.drop(\"FireplaceQu\", axis=1, inplace=True)\n",
    "\n",
    "# Visually inspect X_train\n",
    "X_train\n",
    "\n",
    "# Run this cell without changes\n",
    "\n",
    "# (5c) Concatenate the new dataframe with current X_train\n",
    "X_train = pd.concat([X_train, fireplace_qu_encoded_train], axis=1)\n",
    "\n",
    "# Visually inspect X_train\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing / null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify missing / null variables\n",
    "\n",
    "from sklearn.impute import MissingIndicator\n",
    "\n",
    "# (1) Identify data to be transformed\n",
    "# We only want missing indicators for LotFrontage\n",
    "frontage_train = X_train[[\"LotFrontage\"]]\n",
    "\n",
    "# (2) Instantiate the transformer object\n",
    "missing_indicator = MissingIndicator()\n",
    "\n",
    "# (3) Fit the transformer object on frontage_train\n",
    "missing_indicator.fit(frontage_train)\n",
    "\n",
    "# (4) Transform frontage_train and assign the result\n",
    "# to frontage_missing_train\n",
    "frontage_missing_train = missing_indicator.transform(frontage_train)\n",
    "\n",
    "# # Visually inspect frontage_missing_train\n",
    "frontage_missing_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing missing / null values\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# (1) frontage_train was created previously, so we don't\n",
    "# need to extract the relevant data again\n",
    "\n",
    "# (2) Instantiate a SimpleImputer with strategy=\"median\"\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "# (3) Fit the imputer on frontage_train\n",
    "imputer.fit(frontage_train)\n",
    "\n",
    "# # (4) Transform frontage_train using the imputer and\n",
    "# # assign the result to frontage_imputed_train\n",
    "frontage_imputed_train = imputer.transform(frontage_train)\n",
    "\n",
    "# # Visually inspect frontage_imputed_train\n",
    "frontage_imputed_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_rfe = LinearRegression()\n",
    "select = RFE(lr_rfe, n_features_to_select=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "ss.fit(wine.drop('quality', axis=1))\n",
    "\n",
    "wine_scaled = ss.transform(wine.drop('quality', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select.fit(X=wine_scaled, y=wine['quality'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
